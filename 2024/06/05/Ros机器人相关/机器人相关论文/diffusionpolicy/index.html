<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Diffusion Policy | ALTNT's Hexo Blog</title><meta name="author" content="ALTNT"><meta name="copyright" content="ALTNT"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Diffusion Policy: Visuomotor Policy Learning via Action Diffusion 已知的创新点: 1、将机器人的视觉运动策略表示为一个条件去噪扩散过程 2、Visual conditioning. ——用空间softmax池化(spatial softmax pooling)替换全局平均池化 ——用空间softmax池化(spatial softm">
<meta property="og:type" content="article">
<meta property="og:title" content="Diffusion Policy">
<meta property="og:url" content="http://blog.705553939.xyz/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/index.html">
<meta property="og:site_name" content="ALTNT&#39;s Hexo Blog">
<meta property="og:description" content="Diffusion Policy: Visuomotor Policy Learning via Action Diffusion 已知的创新点: 1、将机器人的视觉运动策略表示为一个条件去噪扩散过程 2、Visual conditioning. ——用空间softmax池化(spatial softmax pooling)替换全局平均池化 ——用空间softmax池化(spatial softm">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://blog.705553939.xyz/img/altnt.jpeg">
<meta property="article:published_time" content="2024-06-05T15:46:21.537Z">
<meta property="article:modified_time" content="2024-08-06T15:53:16.605Z">
<meta property="article:author" content="ALTNT">
<meta property="article:tag" content="Ros机器人">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://blog.705553939.xyz/img/altnt.jpeg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://blog.705553939.xyz/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Diffusion Policy',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-08-06 23:53:16'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/altnt.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="ALTNT's Hexo Blog"><span class="site-name">ALTNT's Hexo Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Diffusion Policy</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-06-05T15:46:21.537Z" title="Created 2024-06-05 23:46:21">2024-06-05</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-08-06T15:53:16.605Z" title="Updated 2024-08-06 23:53:16">2024-08-06</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Diffusion Policy"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="diffusion-policy-visuomotor-policy-learning-via-action-diffusion">Diffusion Policy: Visuomotor Policy Learning via Action Diffusion</h1>
<h2 id="已知的创新点">已知的创新点:</h2>
<p>1、将机器人的视觉运动策略表示为一个条件去噪扩散过程 2、Visual conditioning. ——用空间softmax池化(spatial softmax pooling)替换全局平均池化</p>
<p>——用空间softmax池化(spatial softmax pooling)替换全局平均池化(global average pooling)以保持空间信息(Mandlekar et al(2021))</p>
<p>——将BatchNorm(批归一化)替换为GroupNorm(组归一化)</p>
<p>——Exponential Moving Average（<strong>指数移动平均</strong>)</p>
<p>3、时序扩散transformer</p>
<p>4、<strong>闭环动作序列预测(Closed-loop action-sequence prediction)</strong></p>
<p>5、noise schedule(就是随训练调整预测噪声模型中的参数)————Square Cosine Schedule</p>
<p>6、去噪扩散隐式模型(The Denoising Diffusion Implicit Models ，DDIM)方法</p>
<p>7、动作序列预测的好处</p>
<p>8、扩散策略和 DDPM 完全避开了估计 Z(a,θ) 的问题，而是通过对公式 6 中相同动作分布的得分函数进行建模（Song 和 Ermon，2019）</p>
<p>输入是各种感知信息（比如相机拍到的视频，还有机器人各个关节的位置），而输出的是机器人要执行的动作</p>
<p>Diffusion Policy是一种新型机器人行为生成方法（Robot Action Generation），将机器人的视觉动作策略（Visuomotor Policy）表示为条件去噪扩散过程（Conditional Denoising Diffusion Process）。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714101035927.png" alt><figcaption>1714101035927</figcaption>
</figure>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714101187640.png" alt><figcaption>1714101187640</figcaption>
</figure>
<h2 id="摘要">摘要</h2>
<p><strong>扩散策略是一种新的机器人行为生成方法，它将机器人的视觉运动策略表示为一个条件去噪扩散过程。 </strong></p>
<p>扩散策略学习动作-分布评分函数的梯度，并在推理过程中通过一系列随机朗之万动力学步骤对该梯度场进行迭代优化。</p>
<p>我们发现扩散公式在用于机器人策略时具有强大的优势，包括优雅地处理多模态动作分布，适用于高维动作空间，并表现出令人印象深刻的训练稳定性</p>
<p>为了充分发挥扩散模型在物理机器人视觉运动策略学习中的潜力，本文提出了一系列关键的技术贡献，包括结合后退horizon control(the incorporation of receding horizon control)、视觉调节和时间序列扩散transformer (the incorporation of receding horizon control,visual conditioning, and the time-series diffusion transformer)。</p>
<p>关键词:模仿学习;视觉运动策略;操纵</p>
<h2 id="介绍">1介绍</h2>
<p>从演示中进行策略学习，其最简单的形式可以表述为学习 <strong>将观察映射到行动</strong>的 监督回归任务(即学习将观察结果映射到行动)。</p>
<p>然而，在实践中，与其他监督学习问题相比，预测机器人行为的独特性-例如多模态分布的存在，顺序相关性和高精度的要求-使得这项任务与众不同且具有挑战性。</p>
<p>先前的工作试图通过<strong>探索不同的动作表示</strong>(图1a)来解决这一挑战——使用混合的gaussian（ Mandlekar等人(2021)）、量化动作（Shafiullah等人(2022)）的分类表示，或者通过将策略表示(图1b)从显式转换为隐式，以更好地捕获多模态分布Florence等人(2021);Wu et al(2020)。(介绍以前的动作表示方法的论文)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">如何使用高斯混合解决动作表示问题:</span><br><span class="line">在动作表示中使用高斯混合（Mandlekar 等人，2021 年），其主要思想是将动作的分布建模为多个高斯分布的线性组合。</span><br><span class="line">每个高斯分布都有自己的均值和协方差，通过调整这些参数来拟合数据中的不同模式。这样可以捕捉到动作可能存在的多模态性，即一个动作可能有多种不同的表现形式或分布模式。</span><br><span class="line">例如，在机器人操作任务中，对于某个特定的动作（如抓取物体），可能存在多种不同的抓取方式和力度，这些都可以用不同的高斯分布来表示。然后，通过学习这些高斯分布的参数，使模型能够根据输入的观察结果生成合适的动作。</span><br><span class="line">具体实现过程可能包括收集大量的动作数据，对数据进行预处理和特征提取，然后使用合适的算法来估计高斯混合模型的参数。在预测阶段，根据输入的观察信息，计算每个高斯分布的条件概率，并将它们组合起来得到最终的动作预测。</span><br><span class="line">这种方法的优点是能够灵活地表示复杂的动作分布，但也可能面临计算复杂度较高和参数估计困难等问题。 </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714057682528.png" alt><figcaption>1714057682528</figcaption>
</figure>
<p>图1所示。policy 表示。</p>
<p>a)具有不同类型<strong>动作</strong>表示的显式策略。</p>
<p>b)隐式策略学习以<strong>行动</strong>和<strong>观察</strong>为条件的energy function，并优化最小化energy landscape的行动</p>
<p>c)扩散策略通过学习的梯度场将噪声细化为行动。该公式提供了稳定的训练，允许学习策略准确地建模多模态动作分布，并适应高维动作序列。</p>
<p>在这项工作中，我们试图通过引入一种新形式的机器人视觉运动策略来解决这一挑战，该策略通过“机器人动作空间上的条件去噪扩散过程Ho等人(2020)”扩散策略来生成行为。</p>
<p>在<strong>这个公式中，策略不是直接输出一个动作，而是根据视觉观察推断K次去噪迭代的动作得分梯度(图1c)。这个公式允许机器人策略继承扩散模型的几个关键属性——即显著提高性能。</strong></p>
<p>•<strong>表达多模态动作分布</strong>。通过学习动作得分函数（Song和Ermon(2019)）的梯度，并对该梯度场进行Stochastic Langevin动态采样，扩散策略可以表示任意的归一化分布 （Neal等人(2011)），其中包括多模态动作分布，这是策略学习的一个众所周知的挑战。</p>
<p>•高维输出空间。正如他们令人印象深刻的图像生成结果所证明的那样，扩散模型在高维输出空间中表现出了出色的可扩展性。此属性允许策略共同推断未来操作的序列，而不是单步操作，这对于鼓励时间操作一致性和避免短视规划至关重要。</p>
<p>•稳定的训练。训练基于能量的策略通常需要负采样来估计难以处理的归一化常数，这已知会导致训练不稳定性（Du et al (2020);Florence等人(2021)）。扩散策略通过学习能量函数的梯度来绕过这一要求，从而在保持分布表达性的同时实现稳定的训练。</p>
<p>我们的主要贡献是将上述优势引入机器人领域，并在复杂的现实世界机器人操作任务中展示其有效性。为了成功地将扩散模型应用于视觉运动策略学习，我们提出了以下技术贡献，以提高扩散策略的性能并释放其在物理机器人上的全部潜力:</p>
<p>•闭环动作序列。我们将策略预测高维动作序列的能力与后退水平控制相结合，以实现鲁棒执行。这种设计允许策略以闭环的方式不断地重新规划其行动，同时保持时间行动的一致性——在长期规划和响应性之间实现平衡。</p>
<p>•Visual conditioning.。我们引入了vision conditioned diffusion policy，其中<strong>视觉观察被视为条件</strong>而不是联合数据分布的一部分。在该公式中，无论去噪迭代如何，策略都只提取一次视觉表示，这大大减少了计算量并实现了实时动作推理。（<strong>重点看下这个视觉观察被视为条件怎么实现的，这个只取一次视觉表示，难道以前会取多次？</strong>）</p>
<p>•时序扩散transformer。我们提出了一种新的基于transformer的扩散网络，它最大限度地减少了典型的基于cnn的模型的过度平滑效应，并在需要高频动作变化和速度控制的任务上实现了最先进的性能。（"Over-smoothing"是卷积神经网络（CNN-based models）中可能出现的一种现象，它通常指的是当网络层过多时，模型的每一层都会对输入数据进行平滑处理，导致特征之间的区分度逐渐丧失。这种效应可能会导致模型在深层网络中难以保持有效的特征表示，尤其是在处理图像、图形和其他高维数据时。）</p>
<p>Transformer模型采用了一种不同于传统CNN模型的架构，这使得它能够在一定程度上缓解或解决过度平滑的问题。以下是Transformer模型的一些关键特点，这些特点帮助它避免了CNN模型中常见的过度平滑效应：</p>
<ol type="1">
<li>自注意力机制（Self-Attention）：Transformer模型的核心是自注意力机制，它允许模型在处理序列的任何部分时直接查看序列中的其他部分。这种机制使得模型能够捕捉到长距离依赖关系，而不需要通过多层网络传递信息，从而减少了信息在传递过程中的损失。</li>
<li>全连接层：与CNN使用局部卷积核不同，Transformer模型通过自注意力机制和全连接层处理整个输入序列，这样可以保留更多的全局信息，并减少信息在层与层之间传递时的损耗。</li>
<li>残差连接（Residual Connections）：Transformer模型中广泛使用残差连接，这有助于梯度直接流过网络，从而减少梯度消失问题，并允许模型学习到更加复杂的函数映射。</li>
<li>层标准化（Layer Normalization）：Transformer模型中的层标准化有助于稳定训练过程，它在每一层的输出上进行标准化操作，有助于保持训练过程中的数值稳定性。</li>
<li>可伸缩性（Scalability）：由于自注意力机制的并行性，Transformer模型可以更有效地处理大型数据集和长序列数据，而不会像深层CNN模型那样受到过度平滑的影响。</li>
</ol>
<p>总体而言，Transformer模型通过自注意力机制和残差连接等设计，有效地保持了不同输入之间的区分度，同时避免了信息在深层网络中的丢失，这使得它在处理序列数据时比传统的CNN模型表现更好。</p>
<h2 id="difussion-policy-formulation">difussion policy formulation</h2>
<p>我们将视觉运动机器人策略制定为去噪扩散概率模型 ((ddpm) Ho等(2020))。</p>
<h3 id="扩散概率模型去噪">2.1扩散概率模型去噪</h3>
<p>ddpm是一类生成模型，其中输出生成建模为去噪过程，通常称为随机朗格万动力学(Welling and Teh, 2011)。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714105104195.png" alt><figcaption>1714105104195</figcaption>
</figure>
<p>也可以表示成：<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714105152950.png" alt="1714105152950"></p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714105280029.png" alt><figcaption>1714105280029</figcaption>
</figure>
<p>选择α， γ，σ作为迭代步长k的函数，也称为噪声调度，可以解释为梯度体面过程的学习率调度。略小于1的α已被证明可以提高稳定性(Ho et al(2020))。</p>
<p>有关噪音时间表的详情将于第3.3节讨论。</p>
<h3 id="ddpm-training">2.2DDPM Training</h3>
<p>训练过程首先从数据集中随机抽取未修改的样本x0。对于每个样本，我们随机选择一个去噪迭代k，然后对迭代k采样一个具有适当方差的随机噪声ε k。</p>
<p>噪声预测网络被要求从加了噪声的数据样本中预测噪声。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714105591513.png" alt><figcaption>1714105591513</figcaption>
</figure>
<p>如Ho et al(2020)所示，最小化Eq 3中的损失函数也最小化了使用 <strong>Eq 1的数据分布p(x 0)</strong> 与 <strong>从DDPM q(x 0)抽取的样本分布</strong> 之间的kl -散度的变分下界。</p>
<h3 id="用于视觉运动策略学习的扩散diffusion-for-visuomotor-policy-learning">2.3 用于视觉运动策略学习的扩散(Diffusion for Visuomotor Policy Learning)</h3>
<p>虽然 DDPM 通常用于图像生成（x 是一幅图像），但我们使用 DDPM 来学习机器人的视觉运动策略。</p>
<p>这在公式表述上需要两个主要的修改：1. 将输出 x 改为表示机器人的动作。2. 使去噪过程以输入观察 Ot 为条件。以下段落将讨论每一项修改，图 2 给出了概述。</p>
<p><strong>闭环动作序列预测(Closed-loop action-sequence prediction)</strong>：</p>
<ul class="task-list">
<li><input type="checkbox" disabled>
有效的动作公式应在长时程规划中鼓励时间上的一致性和平滑性，同时允许对意外观察做出迅速反应。为实现这一目标，我们在重新规划之前，<strong>采用扩散模型生成的固定时长的动作序列预测</strong>。具体来说，<strong>在时间步 t，策略将最新的 To 步观察数据 Ot 作为输入，并预测 Tp 步动作，其中 Ta 步动作在机器人上执行，而无需重新规划</strong>。在此，我们<strong>将 To 定义为观察范围，Tp 定义为动作预测范围，Ta 定义为动作执行范围</strong>。这鼓励了时间上的动作一致性，同时保持响应能力。关于 Ta 的影响的更多细节在第 4.3 节中讨论。我们的公式还允许<strong>渐消水平控制（Mayne 和 Michalska，1988）</strong>通过<strong>用上一个动作序列预测为下一个推理设置进行热启动</strong>，<strong>进一步提高动作的平滑性</strong>。</li>
</ul>
<p><strong>视觉观察条件(Visual observation conditioning)：</strong></p>
<p>我们<strong>使用 DDPM 来近似条件分布 p(At|Ot)</strong>，而不是 Janner 等人（2022a）在规划中使用的联合分布 p(At,Ot)。这种公式<strong>使得模型能够根据观察结果预测动作，而无需推断未来状态的成本</strong>，加快了扩散过程并提高了生成动作的准确性。为了捕获条件分布 p(At|Ot)，**我们将公式 1 修改为：$ A_{t}^{k-1}=(<em>{t}^{k}-</em>{}(O_{t}, A_{t}^{k}, k)+(0, ^{2} I)) (4) <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="26.018ex" height="2.149ex" role="img" focusable="false" viewbox="0 -750 11500 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">训</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">练</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">损</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">失</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">从</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">公</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">式</text></g><g data-mml-node="mn" transform="translate(7000,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"/></g><g data-mml-node="mi" transform="translate(7500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">修</text></g><g data-mml-node="mi" transform="translate(8500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">改</text></g><g data-mml-node="mi" transform="translate(9500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">为</text></g><g data-mml-node="mi" transform="translate(10500,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">：</text></g></g></g></svg></mjx-container> =MSE(^{k}, <em>{}(O</em>{t}, _{t}<sup>{0}+</sup>{k}, k)) (5) $**</p>
<p><strong>将观察特征 Ot 从去噪过程的输出中排除，显著提高了推理速度</strong>，更能适应实时控制。这还有助于使视觉编码器的端到端训练可行。关于视觉编码器的详细信息在第 3.2 节中描述。</p>
<figure>
<img src="https://file+.vscode-resource.vscode-cdn.net/Users/altnt/Library/Mobile%20Documents/com~apple~CloudDocs/%E8%AF%BE%E4%BB%B6%E5%8F%8A%E4%BD%9C%E4%B8%9A/learning-notes/myblog/source/_posts/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714108254416.png" alt><figcaption>1714108254416</figcaption>
</figure>
<h2 id="具体实现">具体实现</h2>
<h3 id="network-architecture-options">3.1 Network Architecture Options</h3>
<p>第一个设计决策是<strong>选择εθ的神经网络结构(即噪声预测网络)</strong>。$<em>{}(O</em>{t}, A_{t}^{k}, k) $</p>
<p>在这项工作中，我们研究了两种常见的网络架构类型，卷积神经网络(cnn) Ronneberger等人(2015)和Transformers Vaswani等人(2017)，并比较了它们的性能和训练特征。请注意，噪声预测网络εθ的选择与视觉编码器无关，这将在第3.2节中描述</p>
<h4 id="cnn-based-diffusion-policy">CNN-based Diffusion Policy</h4>
<p>我们采用Janner等人(2022b)的一维时间CNN，并进行了一些修改:</p>
<p>首先，我们仅通过使用Feature-wise Linear Modulation (FiLM 特征线性调制？)（4 Perez等人(2018)）以及去噪迭代k来<strong>调节</strong>观察特征<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.492ex" height="1.95ex" role="img" focusable="false" viewbox="0 -704 1101.3 861.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"/></g><g data-mml-node="TeXAtom" transform="translate(796,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g></g></g></svg></mjx-container></span>上的动作生成过程，从而对条件分布p(At |Ot)进行建模，如图2 (b)所示。</p>
<p>其次，我们仅<strong>预测动作轨迹，而不是预测拼接的观察动作轨迹</strong>。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714105908721.png" alt><figcaption>1714105908721</figcaption>
</figure>
<p>第三，由于与我们使用渐消预测范围的框架不兼容，我们 <strong>移除了</strong> 基于修复的目标状态条件(inpainting-based goal state conditioning) 。然而，使用与观察相同的 FiLM 条件方法，<strong>目标条件(goal conditioning)</strong>仍然是可能的。</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">注:</span><br><span class="line">1、目标条件（goal conditioning）</span><br><span class="line">目标条件（goal conditioning）是一种在机器学习和人工智能中使用的技术，它通过在模型训练或推理过程中引入目标信息来指导模型的学习或决策。</span><br><span class="line"></span><br><span class="line">在本文中提到的扩散模型中，目标条件可以帮助模型根据给定的目标状态来生成更符合期望的动作序列。例如，在机器人操作任务中，目标条件可以是将某个物体移动到特定位置，模型会根据这个目标条件来学习如何生成一系列动作以实现该目标。</span><br><span class="line"></span><br><span class="line">与一般的条件学习不同，目标条件更加明确地指定了最终要达到的状态或目标，使得模型在学习过程中能够更好地聚焦于实现这些目标，从而提高学习效率和生成结果的准确性。</span><br><span class="line"></span><br><span class="line">2、基于修复的目标状态条件(npainting-based goal state conditioning)</span><br><span class="line">基于修复的目标状态条件是一种在模型中用于处理目标状态的方法。</span><br><span class="line"></span><br><span class="line">在本文中，作者提到之前的一些工作（如 Janner 等人，2022a）在规划中使用联合分布 $p(A<span class="emphasis">_t,O_</span>t)$ ，其中可能包含了基于修复的目标状态条件。然而，由于本文所采用的框架利用了渐消预测范围，这种基于修复的目标状态条件与之不兼容，所以作者在他们的方法中移除了该条件。</span><br><span class="line"></span><br><span class="line">需要注意的是，虽然移除了基于修复的目标状态条件，但目标条件仍然可以通过文中提到的用于观察的相同的 FiLM（Feature-wise Linear Modulation）条件方法来实现。</span><br><span class="line">3、FiLM（Feature-wise Linear Modulation）条件方法</span><br><span class="line">FiLM（Feature-wise Linear Modulation）条件方法是一种在深度学习中用于对特征进行条件化处理的技术。</span><br><span class="line"></span><br><span class="line">在本文中，FiLM 条件方法被应用于基于卷积神经网络（CNN）的扩散策略中。具体来说，对于每个卷积层，观察特征 $O<span class="emphasis">_t$ 通过 FiLM 以通道为单位对动作生成过程进行条件化。</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">这种方法使得模型能够根据观察到的信息对动作的生成进行调整，从而更好地捕捉到动作与观察之间的关系，提高模型的性能和泛化能力。</span></span><br></pre></td></tr></table></figure>
<pre><code>![1722498512649](diffusionpolicy/1722498512649.png)</code></pre>
<p>在实践中，我们发现基于cnn的主干在大多数开箱即用的任务上工作得很好，而不需要太多的超参数调优。</p>
<p>然而，当期望的动作序列随时间快速而剧烈地变化时(例如速度命令动作空间)，它的性能很差，这可能是由于时间卷积的<strong>归纳偏差</strong>更倾向于低频信号(Tancik et al(2020))(这种偏差使得 CNN 在处理快速变化的动作序列时，难以准确捕捉到高频的变化信息，从而导致性能下降)。</p>
<p>Tancik 等人（2020）的研究成果为这种现象提供了理论支持。他们的研究表明，<strong>时间卷积在处理信号时，对低频部分具有一定的偏好性</strong>，这可能会限制 CNN 在处理某些特定类型任务时的性能。</p>
<h4 id="time-series-diffusion-transformer">Time-series diffusion transformer</h4>
<p><strong>为了减少CNN模型Tancik等人(2020)的过平滑效应(就上一段讲的cnn的弊端)</strong>，我们引入了一种新颖的基于transformer的 DDPM，它采用了来自 minGPT（Shafiullah 等人，2022 年）的transformer架构来进行动作预测。(????这小节不是讲的是<strong>选择εθ的神经网络结构(即噪声预测网络)</strong>。$<em>{}(O</em>{t}, A_{t}^{k}, k) $吗????,怎么这里变成动作预测了)</p>
<p>带有噪声<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.731ex;" xmlns="http://www.w3.org/2000/svg" width="2.718ex" height="2.554ex" role="img" focusable="false" viewbox="0 -805.6 1201.4 1128.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g><g data-mml-node="mi" transform="translate(783,363) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(783,-315.5) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"/></g></g></g></g></svg></mjx-container></span>的动作作为输入tokens传递到transformer解码器块中，同时将扩散迭代 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewbox="0 -694 521 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"/></g></g></g></svg></mjx-container></span> 的正弦embedding作为第一个token添加到前面。观察 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.492ex" height="1.95ex" role="img" focusable="false" viewbox="0 -704 1101.3 861.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"/></g><g data-mml-node="mi" transform="translate(796,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g></g></svg></mjx-container></span> 通过一个共享的<strong>多层感知机（MLP）</strong>转换为观察embedding序列，然后作为输入特征传递到transformer解码器堆栈中。“梯度”<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.731ex;" xmlns="http://www.w3.org/2000/svg" width="12.153ex" height="2.554ex" role="img" focusable="false" viewbox="0 -805.6 5371.6 1128.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D700" d="M190 -22Q124 -22 76 11T27 107Q27 174 97 232L107 239L99 248Q76 273 76 304Q76 364 144 408T290 452H302Q360 452 405 421Q428 405 428 392Q428 381 417 369T391 356Q382 356 371 365T338 383T283 392Q217 392 167 368T116 308Q116 289 133 272Q142 263 145 262T157 264Q188 278 238 278H243Q308 278 308 247Q308 206 223 206Q177 206 142 219L132 212Q68 169 68 112Q68 39 201 39Q253 39 286 49T328 72T345 94T362 105Q376 103 376 88Q376 79 365 62T334 26T275 -8T190 -22Z"/></g><g data-mml-node="mi" transform="translate(499,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"/></g></g><g data-mml-node="mo" transform="translate(880.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="msub" transform="translate(1269.6,0)"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"/></g><g data-mml-node="mi" transform="translate(796,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g><g data-mml-node="mo" transform="translate(2370.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="msubsup" transform="translate(2815.6,0)"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g><g data-mml-node="mi" transform="translate(783,363) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(783,-315.5) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"/></g></g><g data-mml-node="mo" transform="translate(4017,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="mi" transform="translate(4461.6,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"/></g><g data-mml-node="mo" transform="translate(4982.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container></span>由解码器堆栈的每个相应输出token预测。</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">注:</span><br><span class="line">MLP（Multilayer Perceptron）即多层感知机，也被称为人工神经网络（Artificial Neural Network，ANN）。</span><br><span class="line"></span><br><span class="line">它是一种前馈神经网络模型，由多个神经元（节点）层组成，包括输入层、一个或多个隐藏层以及输出层。</span><br><span class="line"></span><br><span class="line">在 MLP 中，每个神经元接收来自上一层神经元的输入信号，对这些输入进行加权求和，并通过一个非线性激活函数（如 sigmoid、ReLU 等）计算输出。不同层之间的神经元通过权重相互连接，这些权重在训练过程中通过优化算法（如反向传播算法）进行调整，以使得网络能够学习到输入数据与输出目标之间的映射关系。</span><br><span class="line"></span><br><span class="line">MLP 具有很强的学习能力，可以用于解决分类、回归等各种机器学习任务。它能够自动从数据中提取特征，并对复杂的非线性关系进行建模。</span><br></pre></td></tr></table></figure>
<p>在我们的基于状态的实验中，大多数性能最好的策略都是用transformer主干网实现的，特别是在任务复杂性和动作变化率很高的情况下。</p>
<p><strong>然而</strong>，我们发现transformer对超参数更敏感(这意味着与其他模型相比，transformer模型的性能可能会因为超参数的微小变化而产生较大的波动)。Liu等人(2020)的transformer训练困难并不是扩散策略所独有的，而是在更广泛的应用场景中都存在,未来可能会通过改进transformer训练技术或增加数据规模来解决。(改进训练技术可以使模型更好地适应超参数的变化，而增加数据规模可以为模型提供更多的信息，帮助它更好地学习和泛化，从而降低对超参数的敏感性。)</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714106557306.png" alt><figcaption>1714106557306</figcaption>
</figure>
<h4 id="建议">建议</h4>
<p>一般来说，我们建议从基于cnn的扩散策略实现开始，作为新任务的第一次尝试。如果由于任务复杂性或高速率动作变化而导致性能低下，则可以使用Time-series Diffusion Transformer公式来潜在地提高性能，但要付出额外调优的代价</p>
<h3 id="visual-encoder">3.2 Visual Encoder</h3>
<p>视觉编码器将原始图像序列映射到潜在embedding <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.492ex" height="1.95ex" role="img" focusable="false" viewbox="0 -704 1101.3 861.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"/></g><g data-mml-node="mi" transform="translate(796,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g></g></svg></mjx-container></span>中，并<strong>使用扩散策略进行端到端训练(这意味着视觉编码器和扩散策略是作为一个整体进行训练的)</strong>。</p>
<p><strong>不同的摄像机视图使用单独的编码器(每个相机视角都有一个对应的单独编码器。这样可以针对每个视角的特点进行专门的特征提取，更好地捕捉不同视角下的图像特征差异)</strong>，</p>
<p><strong>每个时间步长的图像独立编码</strong>，然后<strong>连接</strong>形成<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.492ex" height="1.95ex" role="img" focusable="false" viewbox="0 -704 1101.3 861.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"/></g><g data-mml-node="mi" transform="translate(796,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g></g></svg></mjx-container></span>(这意味着编码器会分别处理每个时间点的图像，提取其特征,这种方式可以捕捉到图像序列在时间维度上的变化信息，同时也保留了每个时间点的独立特征)。</p>
<p>我们使用标准的ResNet-18(未经预训练)作为编码器，并进行了以下修改:</p>
<p>1)用空间softmax池化(spatial softmax pooling)替换全局平均池化(global average pooling)以保持空间信息(Mandlekar et al(2021))。(池化层的概念非常简单)</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">在原始的 ResNet - 18 中，通常使用全局平均池化来对卷积层的输出进行池化操作，将每个特征图的平均值作为一个特征值。而这里采用了空间 softmax 池化来代替全局平均池化。</span><br><span class="line">空间 softmax 池化会对每个空间位置上的特征值进行 softmax 计算，使得模型能够更加关注图像中的空间位置信息，从而更好地保持空间信息，这对于一些需要依赖空间位置关系的任务是很重要的。</span><br><span class="line">这种修改方法参考了 Mandlekar 等人（2021 年）的研究。</span><br><span class="line"></span><br><span class="line">“Spatial Softmax Pooling”:</span><br><span class="line">“Spatial Softmax Pooling”（空间 Softmax 池化）是一种在计算机视觉和深度学习中用于处理图像或特征图的操作。</span><br><span class="line"></span><br><span class="line">它的主要作用是将特征图上的空间信息转换为概率分布，同时保留空间位置的相关性。</span><br><span class="line"></span><br><span class="line">具体来说，对于给定的特征图，假设其大小为H X W X C（高度为H，宽度为W，通道数为C）。在每个通道上，对每个空间位置(x,y)的特征值进行 Softmax 计算。</span><br><span class="line">Softmax 函数会将这些特征值转换为概率值，使得所有位置的概率值之和为1。这样，每个通道上的特征图就被转换为一个关于空间位置的概率分布。</span><br><span class="line"></span><br><span class="line">通过这种方式，Spatial Softmax Pooling 可以捕捉到特征图中不同位置之间的相对重要性，并且可以将这种空间信息编码为概率分布的形式，方便后续的处理和计算。与传统的全局平均池化或最大池化相比，</span><br><span class="line">它更注重空间位置的关系，能够更好地保留图像的空间结构信息。</span><br><span class="line"></span><br><span class="line">在许多计算机视觉任务中，如姿态估计、目标检测等，Spatial Softmax Pooling 被广泛应用，因为它可以帮助模型更好地理解图像中的空间布局和物体的位置信息。</span><br></pre></td></tr></table></figure>
<p>2)将BatchNorm(批归一化)替换为GroupNorm(组归一化) ( Wu and He(2018))进行稳定训练。当将归一化层(normalization layer)与Exponential Moving Average（<strong>指数移动平均?</strong> He 等人，2020 年）结合使用时，这一点很重要(He et al.2020)(常用于ddpm)。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">BatchNorm（批归一化）是一种常用的神经网络训练技巧，用于解决训练过程中数据分布变化的问题，加速模型的收敛。然而，在某些情况下，BatchNorm 可能会受到批处理大小等因素的影响，导致训练不稳定。这里使用 GroupNorm（组归一化）来代替 BatchNorm。</span><br><span class="line">GroupNorm 将通道分成若干组，然后在每组内进行归一化操作，减少了对批处理大小的依赖，提高了训练的稳定性。这种方法参考了 Wu 和 He（2018 年）的研究。</span><br><span class="line"></span><br><span class="line">指数移动平均是一种在训练过程中对模型参数进行平滑处理的方法，常用于提高模型的稳定性和泛化能力。在 DDPM（扩散模型）中，通常会使用指数移动平均来更新模型的参数。当与归一化层一起使用时，GroupNorm 能够更好地适应这种参数更新方式，从而进一步提高模型训练的稳定性和效果。</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714108254416.png" alt><figcaption>1714108254416</figcaption>
</figure>
<h3 id="noise-schedule噪声计划-就是随训练调整预测噪声模型中的参数">3.3 Noise Schedule(噪声计划? ——就是随训练调整预测噪声模型中的参数)</h3>
<p>由σ、α、γ和作为 k 的函数的附加高斯噪声<img src="https://file+.vscode-resource.vscode-cdn.net/Users/altnt/Library/Mobile%20Documents/com~apple~CloudDocs/%E8%AF%BE%E4%BB%B6%E5%8F%8A%E4%BD%9C%E4%B8%9A/learning-notes/myblog/source/_posts/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714108899983.png" alt="1714108899983">定义已经得到了积极的研究(Ho et al. (2020); Nichol and Dhariwal (2021))。</p>
<p><strong>潜在的noise schedule控制 扩散策略捕捉动作信号的高频和低频特征的 程度</strong>。(<strong>也就是说，通过调整噪声计划中的这些参数，可以改变模型对不同频率信号的处理方式和能力</strong>)</p>
<p>在我们的控制任务中，我们经验地发现iDDPM Nichol和Dhariwal(2021)中提出的<strong>平方余弦时间计划(the Square Cosine Schedule)</strong>最适合我们的任务。</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">“Square Cosine Schedule”（平方余弦计划）是一种用于扩散模型（Diffusion Model）中的噪声调度策略。</span><br><span class="line"></span><br><span class="line">在扩散模型中，通过逐步添加噪声并进行去噪过程来生成数据或学习数据分布。噪声调度策略决定了在每个迭代步骤中添加噪声的方式和强度。</span><br><span class="line"></span><br><span class="line">平方余弦计划具体定义了参数 σ、α、γ 和 εk 随迭代次数 k 的变化方式。它的设计旨在更好地控制扩散过程中高频和低频特征的捕捉程度。</span><br><span class="line"></span><br><span class="line">这种调度策略在一定程度上平衡了模型对不同频率信号的处理能力，使得模型能够更有效地学习数据中的复杂模式和结构。</span><br><span class="line"></span><br><span class="line">在 iDDPM（Improved Denoising Diffusion Probabilistic Models）中提出的 Square Cosine Schedule 经过实验验证，在特定的任务中表现出了良好的性能，能够更好地适应任务需求，提高扩散模型的效果。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="accelerating-inference-for-real-time-control-实时控制加速推理">3.4 Accelerating Inference for Real-time Control 实时控制加速推理</h3>
<p>我们使用扩散过程作为机器人的策略;因此，快速的推理速度对闭环实时控制至关重要。</p>
<p><strong>去噪扩散隐式模型(The Denoising Diffusion Implicit Models ，DDIM)方法Song等人(2021)将训练和推理中的去噪迭代次数解耦，从而允许算法使用更少的迭代进行推理，从而加快过程。(因为去噪迭代次数越多，计算量就越大，所需时间也就越长。减少推理时的迭代次数可以显著提高推理速度，使得模型能够更快地生成结果。)</strong></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">去噪扩散隐式模型（DDIM）方法是一种对传统扩散模型的改进方法，主要用于加速模型的推理过程同时保持较好的生成质量。</span><br><span class="line"></span><br><span class="line">在传统扩散模型中，从随机噪声生成目标数据的过程是通过一系列的去噪步骤来实现的。在训练阶段，模型学习如何逐步去除噪声以恢复原始数据。在推理阶段，同样需要进行类似的去噪步骤来生成新的数据。然而，传统方法在推理时需要进行与训练相同数量的去噪迭代，这可能导致推理速度较慢，尤其是对于实时应用场景来说可能不太理想。</span><br><span class="line"></span><br><span class="line">DDIM 方法的关键思想是解耦训练和推理过程中的去噪迭代次数。具体来说，它通过一种近似的方式，使得在推理时可以使用比训练更少的迭代次数来得到相似质量的结果。</span><br><span class="line"></span><br><span class="line">在 DDIM 中，去噪过程不再严格遵循传统扩散模型的马尔可夫链形式，而是采用了一种隐式的方式来进行去噪。这种方法在一定程度上减少了计算量，从而提高了推理速度。</span><br><span class="line"></span><br><span class="line">此外，DDIM 还通过调整一些参数和策略，使得模型能够在较少的迭代次数下仍然保持较好的生成效果。它在保持扩散模型优点的同时，有效地解决了推理速度慢的问题，使其更适用于对实时性要求较高的应用场景，如机器人控制等。</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在我们的实际实验中，使用DDIM进行100次训练迭代和10次推理迭代，在Nvidia 3080 GPU上实现0.1s的推理延迟。</p>
<h2 id="扩散策略的4个有趣性质">4 扩散策略的4个有趣性质</h2>
<h3 id="模型多模态即多种模式动作分布">4.1模型多模态(即多种模式)动作分布</h3>
<p>在行为克隆文献(behavior cloning literature)中，对人类示范中的多模态分布建模的挑战已被广泛讨论，如 Florence 等人（2021 年）；Shafiullah 等人（2022 年）；Mandlekar 等人（2021 年）。扩散策略能够自然且精确地表达多模态分布，这是其关键优势之一。</p>
<p>直观地说，扩散策略在动作生成中的多模态性源于两个来源——<strong>潜在的随机抽样过程和随机初始化</strong>。</p>
<p>在随机朗之万动力学中，在每个抽样过程开始时，从标准高斯分布中抽取初始样本<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.696ex;" xmlns="http://www.w3.org/2000/svg" width="3.307ex" height="2.519ex" role="img" focusable="false" viewbox="0 -805.6 1461.6 1113.4"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g><g data-mml-node="mi" transform="translate(783,363) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(783,-307.7) scale(0.707)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"/></g></g></g></g></svg></mjx-container></span>，这有助于为最终的动作预测<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.704ex;" xmlns="http://www.w3.org/2000/svg" width="2.685ex" height="2.527ex" role="img" focusable="false" viewbox="0 -805.6 1186.6 1116.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g><g data-mml-node="mi" transform="translate(783,363) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mn" transform="translate(783,-295.7) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"/></g></g></g></g></svg></mjx-container></span>指定不同的可能收敛域。然后，对该动作进行进一步的随机优化，在大量迭代中添加高斯扰动，这使得单个动作样本能够在不同的多模态动作域之间收敛和移动。</p>
<p>图 3 展示了在平面推动任务（下面介绍的“Push T”）中扩散策略的多模态行为的示例，对于所测试的场景没有明确的演示。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714124457490.png" alt><figcaption>1714124457490</figcaption>
</figure>
<h3 id="synergy-with-position-control与位置控制协同">4.2 Synergy with Position Control与位置控制协同</h3>
<p>我们发现<strong>具有位置控制动作空间的扩散策略始终优于具有速度控制velocity control的扩散策略</strong>，如图4所示。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714147061957.png" alt><figcaption>1714147061957</figcaption>
</figure>
<p>Figure 4. Velocity速度 v.s. Position Control位置控制. 从速度控制切换到位置控制时的性能差异。 在BCRNN和BET性能下降的同时，扩散策略能够利用位置优势，提高其性能</p>
<p>这一令人惊讶的结果与最近大多数依赖于速度控制的行为克隆工作形成了鲜明对比,推测这种差异有两个主要原因:</p>
<p><strong>首先</strong>，动作多模态在位置控制模式下比在速度控制模式下更为明显。由于扩散策略比现有方法更好地表达了行动多模态，我们<strong>推测</strong>它本质上比现有方法受这一缺陷的影响更小。</p>
<p><strong>此外</strong>，与速度控制相比，位置控制<strong>受复合误差影响较小</strong>，因此更适合于动作序列预测(如下节所述)。</p>
<ul>
<li><strong>误</strong>差<strong>累</strong>积<strong>:</strong> <strong>在</strong>速<strong>度</strong>控<strong>制</strong>中<strong>，</strong>每<strong>个</strong>动<strong>作</strong>都<strong>会</strong>影<strong>响</strong>下<strong>一</strong>个<strong>动</strong>作<strong>的</strong>起<strong>点</strong>，<strong>因</strong>此<strong>误</strong>差<strong>会</strong>随<strong>着</strong>时<strong>间</strong>推<strong>移</strong>而<strong>累</strong>积<strong>。</strong>而<strong>在</strong>位<strong>置</strong>控<strong>制</strong>中<strong>，</strong>每<strong>个</strong>动<strong>作</strong>都<strong>是</strong>独<strong>立</strong>的<strong>，</strong>因<strong>此</strong>误<strong>差</strong>不<strong>会</strong>累<strong>积</strong>。<strong>这</strong>使<strong>得</strong>位<strong>置</strong>控<strong>制</strong>更<strong>适</strong>合<strong>于</strong>预<strong>测</strong>长<strong>序</strong>列<strong>的</strong>动<strong>作</strong>。</li>
</ul>
<p>因此，扩散策略既不受位置控制的主要缺点的影响，又能更好地利用位置控制的优点。</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">注：</span><br><span class="line"></span><br><span class="line">位置控制 (Position Control):</span><br><span class="line"></span><br><span class="line"> 目标: 控制机械系统或机器人末端执行器达到预定的目标位置。</span><br><span class="line"> 控制方式: 系统直接接收目标位置指令，并通过反馈机制 (如编码器) 测量当前位置。控制器根据目标位置和当前位置之间的误差计算出所需的控制信号 (例如，电机转矩或力)，以驱动系统向目标位置移动。</span><br><span class="line"> 优点:</span><br><span class="line"></span><br><span class="line">  简单直观，易于理解和实现。</span><br><span class="line">  可以实现精确的位置控制，尤其适用于需要高精度的任务。</span><br><span class="line"></span><br><span class="line"> 缺点:</span><br><span class="line"></span><br><span class="line">  可能导致运动轨迹不平稳，因为系统只关注最终位置，而忽略了中间过程。</span><br><span class="line">  对扰动和模型误差敏感，需要精确的模型和校准。</span><br><span class="line"></span><br><span class="line">速度控制 (Velocity Control):</span><br><span class="line"></span><br><span class="line"> 目标: 控制机械系统或机器人末端执行器的运动速度。</span><br><span class="line"> 控制方式: 系统接收目标速度指令，并通过反馈机制 (如速度传感器) 测量当前速度。控制器根据目标速度和当前速度之间的误差计算出所需的控制信号 (例如，电机电压或电流)，以驱动系统达到目标速度。</span><br><span class="line"> 优点:</span><br><span class="line"></span><br><span class="line">  可以实现平滑的运动轨迹，因为系统关注速度变化。</span><br><span class="line">  对扰动和模型误差不太敏感，比位置控制更鲁棒。</span><br><span class="line"></span><br><span class="line"> 缺点:</span><br><span class="line"></span><br><span class="line">  位置控制精度不如位置控制，因为系统只控制速度，而没有直接控制位置。</span><br><span class="line">  需要额外的传感器来测量速度。</span><br><span class="line"></span><br><span class="line"> 应用场景:</span><br><span class="line"></span><br><span class="line">  位置控制: 适用于需要高精度定位的场景，例如 CNC 机床、机器人装配、3D 打印等。</span><br><span class="line">  速度控制: 适用于需要平滑运动的场景，例如机器人行走、车辆控制、传送带等。</span><br></pre></td></tr></table></figure>
<h3 id="动作序列预测的好处">4.3动作序列预测的好处</h3>
<p>之前的研究不使用动作序列预测的原因：</p>
<p>由于难以从高维输出空间（高维输出空间: 序列预测需要一次性预测整个动作序列，这意味着输出空间的维度非常高。例如，如果需要预测 10 个时间步的机械臂动作，而每个时间步包含 7 个关节角度，则输出空间的维度为 70。从如此高维的空间中进行有效的采样是一个挑战，因为可能的动作序列数量非常庞大。）中有效采样，大多数策略学习方法往往避免了序列预测。例如，IBC 在对具有<strong>非平滑能量景观</strong>的高维动作空间<strong>进行有效采样时会遇到困难</strong>。（非平滑能量地形: 在高维动作空间中，目标函数的能量地形可能非常复杂，存在许多局部最优解和非平滑区域。这使得基于梯度的优化方法难以找到全局最优解，也使得采样方法难以有效地探索整个空间。）类似地，BCRNN 和 BET 也难以确定动作分布中存在的模式数（GMM 或 k-means 步长所需要的）。（<strong>多模态分布</strong>: 在许多任务中，可能存在多个不同的动作序列可以实现相同或相似的目标。这意味着动作分布具有多个模态。例如，要将一个物体从 A 点移动到 B 点，可以有多条不同的路径。现有的一些策略学习方法，例如基于高斯混合模型 （GMM） 或 k-means 聚类的方法，<strong>需要预先指定模态数量，这在实际应用中往往难以确定</strong>。）</p>
<p>相反，<strong>DDPM可以很好地扩展输出维度，而不会牺牲模型的表达性</strong>，正如许多图像生成应用程序所证明的那样。</p>
<p>利用这种能力，<strong>扩散策略以高维动作序列的形式表示动作</strong>，它自然地解决了以下问题<strong>(这两个问题是被解决了的)</strong>:</p>
<p>•<strong>时间动作一致性</strong>:以图3为例。</p>
<p>要将T块从底部推入目标，策略可以从左侧或右侧绕过T块。</p>
<p>然而，假设序列中的每个动作被预测为独立的多模态分布(就像在BCRNN和BET中所做的那样)。在这种情况下，可以从不同的模式中绘制连续的动作，从而导致在两个有效轨迹之间交替的紧张动作。</p>
<p>•<strong>对空闲动作的鲁棒性</strong>:当演示暂停并导致相同位置动作或接近零速度动作的序列时，会发生空闲动作。</p>
<p>它在远程操作中很常见，有时也需要像液体倾倒这样的任务。然而，单步策略很容易过度适应这种暂停行为。</p>
<p>例如，BC-RNN和IBC经常在现实世界的实验中陷入困境，因为没有明确地从训练中移除空闲动作。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714148799685.png" alt><figcaption>1714148799685</figcaption>
</figure>
<h3 id="training-stability">4.4 Training Stability</h3>
<p>IBC在理论上应该具有与扩散策略相似的优势。然而，由于IBC固有的训练不稳定性，在实践中获得可靠和高性能的IBC结果是具有挑战性的(2022)。</p>
<p>图6显示了整个训练过程中的训练误差峰值和不稳定的评估性能，使得超参数转向变得关键，检查点选择变得困难。因此，Florence等人(2021)评估了每个检查点，并报告了表现最佳的检查点的结果。在实际环境中，此工作流需要对硬件上的许多策略进行评估，以选择最终策略。在这里，我们讨论为什么扩散策略在训练中明显更加稳定</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714149036858.png" alt><figcaption>1714149036858</figcaption>
</figure>
<h4 id="为什么用于隐式策略的基于能量的模型ebm难以训练">4.4.1为什么用于隐式策略的基于能量的模型(EBM)难以训练:</h4>
<p>隐式策略使用Energy-Based Model (EBM)表示动作分布:</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714149081417.png" alt><figcaption>1714149081417</figcaption>
</figure>
<p>where <strong>Z(o,θ)是一个难以处理的归一化常数 (相对于a)</strong></p>
<p>为了训练用于隐式策略的基于能量的模型(EBM)，<strong>使用了InfoNCE-style的loss函数</strong>，它等于Eq 6的负对数似然:</p>
<p><img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714149188951.png" alt="1714149188951"><strong>(其中涉及到当前的样本(o, a)的能量项以及一组负样本(o, )的能量项。)</strong></p>
<p>在这个式子中，使用一组负样本<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714149285457.png" alt="1714149285457">来估计难以处理的<strong>归一化常数Z(o，θ)(即上面的难以处理的归一化常数</strong>)。<strong>但是,在实践中，已知负采样的不准确性会导致EBM的训练不稳定;等等。(2022)。</strong></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">在机器学习和数据分析的背景下：</span><br><span class="line"></span><br><span class="line"><span class="strong">**负样本**</span>：通常是指与我们感兴趣的正类别或目标类别相反的样本。例如，如果我们的目标是识别“猫”的图片（正样本），那么不是“猫”的图片（比如狗、汽车、风景等）就可以被视为负样本。</span><br><span class="line"></span><br><span class="line"><span class="strong">**负采样**</span>：是一种在处理数据时采用的采样技术。当数据集中正样本和负样本的数量不平衡，或者为了降低计算复杂度时，可能会采用负采样。</span><br><span class="line"></span><br><span class="line">负采样的基本思想是从大量的潜在负样本中选取一部分作为实际使用的负样本。例如，在训练一个文本分类模型时，如果一个词与某个特定的词有上下文关系（正样本），那么从其他大量不具有这种上下文关系的词中随机选取一些作为负样本，用于模型的训练。</span><br><span class="line"></span><br><span class="line">负采样的优点包括减少计算量、平衡数据类别、增加模型的泛化能力等。但它的缺点是采样的随机性可能导致选取的负样本不能很好地代表整体的负样本分布，从而影响模型的训练效果。</span><br><span class="line"></span><br><span class="line">您是在学习相关知识还是在实际应用中遇到了与负样本和负采样相关的问题呢？ </span><br></pre></td></tr></table></figure>
<h4 id="扩散策略和-ddpm为什么好训练">4.4.2扩散策略和 DDPM为什么好训练:</h4>
<p><strong>扩散策略和 DDPM 完全避开了估计 Z(a,θ) 的问题，而是通过对公式 6 中相同动作分布的得分函数进行建模（Song 和 Ermon，2019）题</strong>:</p>
<p>：$ <em>{a} log p(a | o)=-</em>{a} E_{}(a, o)-<em>{=0} -</em>{}(a, o) $ ，————————(8)</p>
<p>其<strong>中噪声预测网络 εθ(a,o) 近似于得分函数 ∇a log p(a|o) 的负值（Liu 等人，2022）</strong>，这与归一化常数 Z(o,θ) 无关。</p>
<p>因此，<strong>扩散策略的推理（公式 4）和训练（公式 5）过程都不涉及对 Z(o,θ) 的评估</strong>，从而使扩散策略的训练更稳定。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714149501755.png" alt><figcaption>1714149501755</figcaption>
</figure>
<h3 id="与控制理论的联系">4.5与控制理论的联系</h3>
<p>当任务非常简单时，扩散策略具有简单的极限行为；这可能使我们能够从控制理论中获得一些严格的理解。</p>
<p>考虑这样一种情况，我们有一个线性动态系统，以标准状态空间形式存在，我们希望对其进行控制：</p>
<p><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="30.629ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 13538.1 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/></g><g data-mml-node="TeXAtom" transform="translate(502,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g></g><g data-mml-node="mo" transform="translate(1988.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(3044.5,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g><g data-mml-node="msub" transform="translate(3794.5,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/></g><g data-mml-node="TeXAtom" transform="translate(502,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g><g data-mml-node="mo" transform="translate(4824,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="mi" transform="translate(5824.2,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"/></g><g data-mml-node="msub" transform="translate(6583.2,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="TeXAtom" transform="translate(562,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g><g data-mml-node="mo" transform="translate(7672.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="msub" transform="translate(8672.9,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"/></g><g data-mml-node="TeXAtom" transform="translate(749,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g><g data-mml-node="mo" transform="translate(9727.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="msub" transform="translate(10171.9,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"/></g><g data-mml-node="TeXAtom" transform="translate(749,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g><g data-mml-node="mo" transform="translate(11226.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mn" transform="translate(11615.1,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"/></g><g data-mml-node="msub" transform="translate(12115.1,0)"><g data-mml-node="mo"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="TeXAtom" transform="translate(311,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"/></g></g></g><g data-mml-node="mo" transform="translate(13149.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container> 。</p>
<p>现在想象一下，我们从一个线性反馈策略获得演示（展开）：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="10.577ex" height="1.902ex" role="img" focusable="false" viewbox="0 -683 4675.1 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="TeXAtom" transform="translate(562,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g><g data-mml-node="mo" transform="translate(1145,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mo" transform="translate(2200.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="mi" transform="translate(2978.8,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"/></g><g data-mml-node="msub" transform="translate(3867.8,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/></g><g data-mml-node="TeXAtom" transform="translate(502,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g></g></g></svg></mjx-container> 。</p>
<p>例如，这个策略可以通过解决像线性二次调节器这样的线性最优控制问题来获得。模仿这个策略不需要扩散的建模能力，但作为一个合理性检查，我们可以看到扩散策略做了正确的事情。</p>
<p>特别是，当预测范围是一个时间步长，即 Tp = 1 时，可以看出使<strong>损失函数</strong> $ =MSE(^{k}, <em>{}(s</em>{t},-K s_{t}+^{k}, k)) (9) <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="66.334ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 29319.8 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">最</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">小</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">化</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mo" transform="translate(4222.2,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"/></g><g data-mml-node="mo" transform="translate(4944.4,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"/></g><g data-mml-node="mo" transform="translate(5666.7,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"/></g><g data-mml-node="mo" transform="translate(6388.9,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"/></g><g data-mml-node="mi" transform="translate(6888.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">最</text></g><g data-mml-node="mi" transform="translate(7888.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">优</text></g><g data-mml-node="mi" transform="translate(8888.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">去</text></g><g data-mml-node="mi" transform="translate(9888.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">噪</text></g><g data-mml-node="mi" transform="translate(10888.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">器</text></g><g data-mml-node="mo" transform="translate(11888.9,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(12277.9,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mi" transform="translate(12797.9,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(13142.9,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"/></g><g data-mml-node="mi" transform="translate(13692.9,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"/></g><g data-mml-node="mi" transform="translate(14242.9,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(14814.9,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/></g><g data-mml-node="mi" transform="translate(15283.9,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(15628.9,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"/></g><g data-mml-node="mi" transform="translate(16113.9,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(16713.9,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(17591.9,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"/></g><g data-mml-node="mi" transform="translate(18076.9,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mi" transform="translate(18596.9,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"/></g><g data-mml-node="mi" transform="translate(19062.9,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"/></g><g data-mml-node="mi" transform="translate(19360.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">中</text></g><g data-mml-node="mi" transform="translate(20360.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(21360.9,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mi" transform="translate(21880.9,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(22225.9,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(22825.9,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"/></g><g data-mml-node="mi" transform="translate(23310.9,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(23655.9,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/></g><g data-mml-node="mi" transform="translate(24124.9,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"/></g><g data-mml-node="mi" transform="translate(24590.9,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(25041.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mo" transform="translate(25653.1,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"/></g><g data-mml-node="mo" transform="translate(26375.3,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"/></g><g data-mml-node="mo" transform="translate(27097.6,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"/></g><g data-mml-node="mo" transform="translate(27819.8,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"/></g><g data-mml-node="mi" transform="translate(28319.8,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">由</text></g></g></g></svg></mjx-container> _{}(s, a, k)=[a+K s] $ 给出，其中 σk 是去噪迭代 k 上的方差。</p>
<p>此外，在推理时，DDIM 采样将收敛到 a = -Ks 处的全局最小值。</p>
<p>轨迹预测(Tp &gt; 1)自然随之而来。为了预测<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714234892103.png" alt="1714234892103">是<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.826ex" height="1.357ex" role="img" focusable="false" viewbox="0 -442 807.3 599.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g></g></svg></mjx-container></span>的函数，最佳去噪器(diffusion model中的dinoiser)将产生<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714234914791.png" alt="1714234914791">;</p>
<p>所有涉及到<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.385ex" height="1.359ex" role="img" focusable="false" viewbox="0 -443 1054.3 600.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"/></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g></g></svg></mjx-container></span>的项期望都是零。</p>
<p>这表明，为了完美地克隆依赖于状态的行为，学习者必须隐式学习(任务相关)动态模型(Subramanian和Mahajan (2019);Zhang et al(2020))。</p>
<p>如果设备(plant)或策略是非线性的，那么预测未来的动作可能会变得更具挑战性，并且再次涉及多模态预测。</p>
<h2 id="evaluation">5 Evaluation</h2>
<p>我们系统地评估了4个基准中的15个任务的扩散策略(Florence等人(2021);Gupta等人</p>
<p>(2019);Mandlekar et al (2021);Shafiullah et al(2022)。</p>
<p>该评估套件包括模拟和真实环境、单任务和多任务基准、完全驱动和欠驱动系统、刚性和流体对象。我们发现，在所有测试的基准测试中，扩散策略始终优于先前的最先进技术，平均成功率提高了46.9%。在下面的部分中，我们将提供每个任务的概述，我们对该任务的评估方法以及我们的关键要点。</p>
<h3 id="仿真环境和数据集">5.1仿真环境和数据集</h3>
<p><strong>Robomimic Mandlekar et al. (2021) 是一个大型机器人操作基准，旨在研究模仿学习和离线强化学习。基准测试包括5个任务，每个任务都有一个精通的人(PH)远程操作演示数据集，其中4个任务(总共9个变体)有精通/非精通的人(MH)混合演示数据集。对于每个变体，我们报告了基于状态和基于图像的观测结果。表3总结了每个任务的属性。</strong></p>
<p><strong>Push-T adapted from IBC Florence et al. (2021)</strong>,</p>
<p>需要用圆形末端执行器(蓝色)推动t形块(灰色)到固定目标(红色)。T块和末端执行器的随机初始条件增加了变异。该任务需要利用复杂和接触丰富的对象动力学来精确地推动T块，使用点接触。</p>
<p>有两种变体:一种是RGB图像观测，另一种是从T块的底真位姿获得的9个2D关键点，两者都具有对effeffector位置的本体感觉。</p>
<p><strong>Multimodal Block Pushing adapted from BET Shafiullah et al. (2022)</strong>,</p>
<p>该任务通过推入两个块按使得任意顺序分成两个正方形。来测试策略对多模态动作分布建模的能力</p>
<p>演示数据是由脚本化的oracle生成的，可以访问groundtruth状态信息。这个oracle随机选择一个初始块来推送，并将其移动到一个随机选择的正方形。然后将剩余的块推入剩余的方块中</p>
<p><strong>3. 什么是Diffusion Policy？</strong></p>
<p>Diffusion Policy是一种新型机器人行为生成方法（Robot Action Generation），将机器人的视觉动作策略（Visuomotor Policy）表示为条件去噪扩散过程（Conditional Denoising Diffusion Process）。这是来自论文摘要里的一句介绍，但我想大多数和我一样非专业背景的人看到这段话应该是一脸懵，每个字都认识放在一起就不知道什么意思。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1713977280187.png" alt><figcaption>1713977280187</figcaption>
</figure>
<p>关于什么是Diffusion Policy，迟宬有一段很好的解释：Diffusion Policy其实解决的是一个机器人输出的问题，过往的很多工作大家都注重在解决输入的问题，但机器人最终要执行，我们的工作就在于解决机器人动作和输出的问题。更确切地说，我们的创新聚焦于机器人的动作端而非输入端，在输入端使用的是非常普通的东西。尽管输入端有很多可以提高的地方，但机器人学习方法必须注重输出端，先前的算法在输出端的表现都不够好。因此，无论输入端有多么创新，如果输出端表现不佳，就像"茶壶煮饺子倒不出"一样，将无法发挥潜力。</p>
<p>RSS 2023宋舒然有一段对Diffusion Policy的讲解视频，也非常清晰。</p>
<figure>
<video src="diffusionpolicy/1713977431779.mp4" controls><a href="diffusionpolicy/1713977431779.mp4"></a></video><figcaption>1713977431779</figcaption>
</figure>
<p><strong>Diffusion Policy和Diffusion Model的关系</strong></p>
<p>Diffusion Policy可以理解为Diffusion Model在机器人领域的应用。大家都知道Diffusion Model在图像领域的应用产生了非常好的图像生成模型，比如Stable Diffusion这些，比GAN这类图像生成模型的效果好很多。同样的，Diffusion Policy可以理解为这套Diffusion Model在机器人动作生成领域的应用，尤其是部署到物理机器人领域的动作生成。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1713977512026.png" alt><figcaption>1713977512026</figcaption>
</figure>
<p><strong>4. 为什么用Diffusion Policy？</strong></p>
<p><strong>Diffusion Policy解决的核心问题</strong></p>
<p>从最简单的形式来看，从演示中学习策略可以被表述为学习将观察映射到动作的监督回归任务。然而，在实践中，预测机器人动作有一系列挑战，比如存在多模态分布、时序相关性和训练稳定性的要求。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1713977555135.png" alt><figcaption>1713977555135</figcaption>
</figure>
<p><strong>解决机器人Multi-Modal分布问题</strong></p>
<p>机器人Multi-Modal的问题，简单理解，现实世界中解决某一特定任务的方式是多样的，而不是唯一的。但神经网络预测只能给出单一的方式，无法应对可能有多种方式的任务情况。</p>
<p>关于什么是机器人Multi-Moda问题，迟宬给了非常清晰的解释：假设我现在在开车，前面有一棵树。比如说，我雇佣了100个司机来解决这个问题。在这种情况下，有可能有50个司机选择往左拐，绕过树的左边，还有50个司机选择从树的右边绕过去。在这种情况下，往左绕和往右绕都是完全合理的。然而，当我们将所有这些解决方案合并为一个时，问题就变成了一个多模态分布，即我看到的相同场景有两种不同的选择。这对传统神经网络的预测来说并不友好，因为它通常使用均方误差（MSE）损失进行训练，而这无法有效处理Multi-Modal情况。</p>
<p>前馈神经网络本质上是一个函数，即对于给定输入，只有一种输出。然而，在某些情况下，一个输入可能对应两种不同的输出。这导致了一个问题，即我想要神经网络执行的任务和它能够执行的任务存在冲突。强行让神经网络处理这种情况，通常是通过预测一个中间值，试图最小化与数据之间的距离。但这可能导致不符合预期的行为，例如直接往树上撞。为了解决这个问题，引入了概率分布，使得神经网络不再是一个输入一个输出的函数，而是一个输入可以有多个输出的函数。这种方法提供了更大的灵活性，可以表示各种概率分布，解决了原有方法的限制。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1713977634123.png" alt><figcaption>1713977634123</figcaption>
</figure>
<p>引入概率分布的方法提供了更大的灵活性，让机器人有机会在相同的情况下选择不同的行为，从而避免陷入不可预测的循环。这种非确定性的特性在实际应用中表现出很大的优势，可以防止算法陷入一成不变的状态。但这和传统机器人控制需要对机器人动作严格控制的思路相违背，每次只执行一项任务，整个机器人系统都被认为是受到严格控制的。这也是为什么大多数人没有把机器人动作生成表现为一个概率分布的原因。</p>
<p>但仔细想下人类在决策时也具有一定的非确定性，即在相同情境下可能做出不同选择。比如说，就像我刚才说的，正前方有棵树。你可能今天心情好，你就往右拐；今天心情不好，你就往左拐。这种非确定性对人类来说可能是一种优势，而不是劣势，对机器人同样如此。举例来说，假设我在机器人的算法里有个bug，就是看到一个锥筒，机器人就会绕着它打转。如果我的算法是确定性的，比如说你现在在这条路上开车，我往路上扔一个锥桶，你就开始绕着这个锥桶打转，可能一辈子也开不出来。然而，如果我的机器人预测不是单一模型，而是一个概率分布，有一定的概率它会绕着打转，有一定的概率它会往直走，这样它就能够突破这个无穷打转的情况，最终回到正常的状态。这个性质在实际应用中对提高算法的鲁棒性有很大的影响，它可以防止算法陷入在某些不太熟悉的情况下一直打转的困境。</p>
<p><strong>Action Space Scalability的问题</strong></p>
<p>关于Action Space Scalabiltiy或者sequential correlation问题，我简单理解就是机器人对未来动作的预测不应该只局限于眼前的一步两步动作，而应该更有前瞻性，可以往前预测数十步动作。</p>
<p>针对这个问题，迟宬给了非常清晰的解释：数据预测有两种方法：一是直接输出一个数值，另一种是将可能的数值分成几个区间，进行离散预测。在预测Multi-Modal Action的时候，人们倾向于采用离散预测，将连续值问题转化为分类问题，但这样做涉及的算力成本很高，尤其在处理高维空间时。此外，针对机器人控制问题，如果采用分类方法，每一步都需要预测下一步要执行的动作，而实际需求是希望一次性预测多步动作，这就涉及到了连续控制中的动作一致性问题。解决这个问题的挑战在于平衡成本和对高维连续控制的需求。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1713977763457.png" alt><figcaption>1713977763457</figcaption>
</figure>
<p>假设我们仍然在进行驾驶操作。我们有选择往左或往右拐的能力，将这个过程比喻为方向盘的控制，这是唯一的控制维度。我们将这个控制维度划分成了100个段。接着，我通过神经网络让它在这100个段中选择我们要采取的方向。这种方法理论上是可行的，但问题在于实施的成本非常高昂。如果我们只有一个维度，例如方向盘，那么使用分类是可行的。但假设我要控制的是一个具有六个自由度的机械手，甚至考虑到夹爪开关，有七个自由度，这时如果我要对其进行分类，就不再是在一个维度上切分成100份，而是每个维度都要切分成1000份。然后，将所有这些切分的部分相乘，才能得到我们整个空间的方法。如果采用这种方法，成本将会非常非常高。随着维度的增加，成本会呈指数级增长。</p>
<p>我们再回到了之前提到的问题。假设我们在驾驶车辆，我们可以在下一步稍微往左偏一点，再下一步再进一步左偏。实际上，我们所绘制的行车轨迹有两种可行的选择。一种是持续向左开，从左侧绕过去，一直保持这种路径。另一种是持续向右开，从右侧绕过去。在预测这个动作时，我们可以逐步进行预测，即在每个时刻，预测下一步应该怎么走。然而，采用这种方式可能会导致问题，例如，如果我稍微向左偏了一点，我可能会左右摇摆；如果我稍微向右偏了一点，也有可能左右摇摆。这个问题被称为动作不一致（Action Inconsistent），即当我希望向左行驶时，神经网络的预测中仍然存在一定概率是向右的情况，这时候就会发现决策非常犹豫，时而向左，时而向右，这是一个问题。</p>
<p>在我刚刚提到的分类中，由于它们预测高维空间的成本非常高，因为它们只能预测一步，接下来的步骤是什么。如果再加上更多的步骤，维度就会变得越来越高，它们就无法胜任。然而，实际上我们现在追求的是具有以下特性的方法：不仅可以预测每一步，而且可以在高维连续控制中实现。对于我们来说，我们可以直接预测未来每一步，无论是接下来的20步还是100步，是向左还是向右，而不是在每一步预测之后再执行，再决定下一步该怎么走。</p>
<p><strong>Training Stability问题</strong></p>
<p>Diffusion Policy和其他使用生成式模型的策略比，他的最大特点是训练过程非常稳定。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1713978152791.png" alt><figcaption>1713978152791</figcaption>
</figure>
<p>关于训练稳定性，迟宬的进一步解释是：在Robot Learning领域，机器人动作执行主要有三种方法：包括<strong>直接回归</strong>、<strong>分类预测</strong>和<strong>生成式模型</strong>。</p>
<p>第一类回归，即将神经网络视为一个函数，输入是图片，输出是一个动作。这是最常见的方法，绝大多数强化学习都采用这种方式。然而，这种方法存在一些问题，正如之前提到的。</p>
<p>第二类分类预测，这种方法通过预测分类来生成动作，前文已经大致描述，不再详细赘述。</p>
<p>第三类生成模型，理论上所有的生成模型都可以预测连续的多模态分布，但很多生成模型的问题是训练不稳定。</p>
<p>基于Diffusion Model的第三类方法具有一个重要的优势，即训练非常稳定。这也是为什么Diffusion Model当前在图像生成方面取得了成功，而当时的生成对抗网络（GAN）并没有成功的原因。在当时，GAN在学术界能够产生一些不错的效果，但当你真的将其应用于产品时，你会发现非常困难。要训练一个有效的GAN，你需要疯狂地调整参数，然后才能训练出可用的生成器。</p>
<p>而Diffusion方法的强大之处在于，它的性能不逊色于GAN，但其训练过程非常稳定。基本上，你可以随便调整参数，生成器就能够输出结果，可能效果不是最优的，但基本上都能work。同时，这也解释了为什么像Stable Diffusion这样的方法，以及现在各种图像生成模型能够在如此庞大的数据集上进行训练，这是因为它们的训练非常稳定。如果你在如此大规模的数据上使用其他方法进行训练，可能会在训练一段时间后出现奇怪的问题，模型无法进一步优化。</p>
<p><strong>5. 采访中提到的其他问题</strong></p>
<p><strong>Diffusion Policy和RL以及Imitational Learning是什么关系？</strong></p>
<p>在Robot Learning领域，机器人操作比较常用的两个路径是强化学习（Reinforcement Learning）和模仿学习（Imitation Learning），Diffusion policy并不与强化学习和模仿学习冲突，它可以应用于两者。该方法是一种策略逻辑，适用于输入图像并输出相应动作的情境。在论文中，我们使用了模仿学习，即由人类遥控机器人执行动作，收集数据，并通过学习将其转化为策略。这种学习过程通过遥控机器人完成一系列动作开始，然后将其迁移到机器人身上。输入数据包括过去几帧的图像，而输出涉及对未来动作的预测。</p>
<p>很多强化学习的人，他们使用强化学习在模拟器中生成大量数据。在这个过程中，为了加速训练，RL policy的输入不是图片，而是一些低维度的底层状态信息。但是由于这些状态信息在现实环境里是无法获得的，因此这个RL policy不能直接用于驱动机器人。这个时候，他们会把RL policy生成的数据用于训练一个图片作为输入的模仿学习策略，这被称为蒸馏。在这种情况下，模仿的对象并非人类，而是一个强化学习“代理”（Agent）。这也是这种方法的应用之一。</p>
<p><strong>操作（Manipulation）和移动（Locomotion）的训练有什么不同？</strong></p>
<p>RL在移动有更好的效果，Sim2Real Gap的问题相对好解决；但在操作，RL存在最大的问题是Sim2Real Gap没法很好的解决。对于操控而言，需要考虑的因素较多，其中一个关键区别是在机器人操作中除了需要考虑机器人本身的物理特性，同时还要适应复杂多变的环境和被操作物体。操控涉及与各种各样的物体进行交互，每个物体都具有独特的物理特性，如重心、摩擦力和动力学。这些在模拟器中难以准确模拟，即便能够模拟，精度通常较低，速度较慢。相比之下，对于locomotion，外界环境大多可以视为一个刚体，物理特性基本可以忽略。这使得可以花费更多时间来建立机器人本体的精确物理模型，以及设计更复杂的物理引擎。这是为什么RL更适合Locomotion，而对有物理机器人部署Manipulation没有那么好的效果。</p>
<p><strong>Diffusion Policy目前会存在什么问题，未来有哪些工作？</strong></p>
<p>目前最大的问题不是Policy本身，而是数据。训练数据对于机器人执行特定任务至关重要。尽管我们已经积累了一些关于遥控机器人执行任务的数据，但要将其部署到实际应用中，比如设计一个家用机器人来洗碗，就需要更大规模、更丰富多样的数据集，类似于ChatGPT的规模。确保机器人能够在各种家庭环境中表现出足够的稳健性。目前，最大的挑战在于如何有效地收集大量、多样化的数据。这是下一步研究的关键，通过数据收集和训练，期望能够解决当前面临的问题，同时也认识到可能会有新的挑战随着数据规模的增加而浮现。</p>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714062874734.png" alt><figcaption>1714062874734</figcaption>
</figure>
<figure>
<img src="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/1714062874734.png" alt><figcaption>1714062874734</figcaption>
</figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://blog.705553939.xyz">ALTNT</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://blog.705553939.xyz/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/">http://blog.705553939.xyz/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/diffusionpolicy/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA/">Ros机器人</a></div><div class="post_share"><div class="social-share" data-image="/img/altnt.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/%E4%BA%91%E6%9C%BA%E5%99%A8%E4%BA%BA/" title="云机器人"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">云机器人</div></div></a></div><div class="next-post pull-right"><a href="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/GenerativeSkillChainingLong-HorizonSkillPlanningwithDiffusionModels/" title="Generative Skill Chaining: Long-Horizon Skill Planning with Diffusion Models"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next</div><div class="next_info">Generative Skill Chaining: Long-Horizon Skill Planning with Diffusion Models</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%A8%A1%E4%BB%BF%E5%AD%A6%E4%B9%A0/" title="模仿学习"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-05</div><div class="title">模仿学习</div></div></a></div><div><a href="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/ros%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/ROS%20%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/" title="ROS通信机制"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-05</div><div class="title">ROS通信机制</div></div></a></div><div><a href="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/GenerativeSkillChainingLong-HorizonSkillPlanningwithDiffusionModels/" title="Generative Skill Chaining: Long-Horizon Skill Planning with Diffusion Models"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-05</div><div class="title">Generative Skill Chaining: Long-Horizon Skill Planning with Diffusion Models</div></div></a></div><div><a href="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/ros%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/2.1%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/00%20%E6%A6%82%E5%BF%B5/" title="Ros通信机制-话题通信"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-05</div><div class="title">Ros通信机制-话题通信</div></div></a></div><div><a href="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/%E6%8E%A5%E4%B8%8B%E6%9D%A5%E5%8F%AF%E8%83%BD%E7%9C%8B%E7%9A%84%E8%AE%BA%E6%96%87/" title="接下来可能看的论文"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-05</div><div class="title">接下来可能看的论文</div></div></a></div><div><a href="/2024/06/05/Ros%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9B%B8%E5%85%B3/ros%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/2.1%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/01.base%20example/" title="Ros通信机制-话题通信2"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-05</div><div class="title">Ros通信机制-话题通信2</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/altnt.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">ALTNT</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ALTNT"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#diffusion-policy-visuomotor-policy-learning-via-action-diffusion"><span class="toc-number">1.</span> <span class="toc-text">Diffusion Policy: Visuomotor Policy Learning via Action Diffusion</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%B2%E7%9F%A5%E7%9A%84%E5%88%9B%E6%96%B0%E7%82%B9"><span class="toc-number">1.1.</span> <span class="toc-text">已知的创新点:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.2.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.3.</span> <span class="toc-text">1介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#difussion-policy-formulation"><span class="toc-number">1.4.</span> <span class="toc-text">difussion policy formulation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B%E5%8E%BB%E5%99%AA"><span class="toc-number">1.4.1.</span> <span class="toc-text">2.1扩散概率模型去噪</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ddpm-training"><span class="toc-number">1.4.2.</span> <span class="toc-text">2.2DDPM Training</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E4%BA%8E%E8%A7%86%E8%A7%89%E8%BF%90%E5%8A%A8%E7%AD%96%E7%95%A5%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%89%A9%E6%95%A3diffusion-for-visuomotor-policy-learning"><span class="toc-number">1.4.3.</span> <span class="toc-text">2.3 用于视觉运动策略学习的扩散(Diffusion for Visuomotor Policy Learning)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.5.</span> <span class="toc-text">具体实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#network-architecture-options"><span class="toc-number">1.5.1.</span> <span class="toc-text">3.1 Network Architecture Options</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#cnn-based-diffusion-policy"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">CNN-based Diffusion Policy</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#time-series-diffusion-transformer"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">Time-series diffusion transformer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BB%BA%E8%AE%AE"><span class="toc-number">1.5.1.3.</span> <span class="toc-text">建议</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#visual-encoder"><span class="toc-number">1.5.2.</span> <span class="toc-text">3.2 Visual Encoder</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#noise-schedule%E5%99%AA%E5%A3%B0%E8%AE%A1%E5%88%92-%E5%B0%B1%E6%98%AF%E9%9A%8F%E8%AE%AD%E7%BB%83%E8%B0%83%E6%95%B4%E9%A2%84%E6%B5%8B%E5%99%AA%E5%A3%B0%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0"><span class="toc-number">1.5.3.</span> <span class="toc-text">3.3 Noise Schedule(噪声计划? ——就是随训练调整预测噪声模型中的参数)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#accelerating-inference-for-real-time-control-%E5%AE%9E%E6%97%B6%E6%8E%A7%E5%88%B6%E5%8A%A0%E9%80%9F%E6%8E%A8%E7%90%86"><span class="toc-number">1.5.4.</span> <span class="toc-text">3.4 Accelerating Inference for Real-time Control 实时控制加速推理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%A9%E6%95%A3%E7%AD%96%E7%95%A5%E7%9A%844%E4%B8%AA%E6%9C%89%E8%B6%A3%E6%80%A7%E8%B4%A8"><span class="toc-number">1.6.</span> <span class="toc-text">4 扩散策略的4个有趣性质</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%A4%9A%E6%A8%A1%E6%80%81%E5%8D%B3%E5%A4%9A%E7%A7%8D%E6%A8%A1%E5%BC%8F%E5%8A%A8%E4%BD%9C%E5%88%86%E5%B8%83"><span class="toc-number">1.6.1.</span> <span class="toc-text">4.1模型多模态(即多种模式)动作分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#synergy-with-position-control%E4%B8%8E%E4%BD%8D%E7%BD%AE%E6%8E%A7%E5%88%B6%E5%8D%8F%E5%90%8C"><span class="toc-number">1.6.2.</span> <span class="toc-text">4.2 Synergy with Position Control与位置控制协同</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E4%BD%9C%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E7%9A%84%E5%A5%BD%E5%A4%84"><span class="toc-number">1.6.3.</span> <span class="toc-text">4.3动作序列预测的好处</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#training-stability"><span class="toc-number">1.6.4.</span> <span class="toc-text">4.4 Training Stability</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8%E4%BA%8E%E9%9A%90%E5%BC%8F%E7%AD%96%E7%95%A5%E7%9A%84%E5%9F%BA%E4%BA%8E%E8%83%BD%E9%87%8F%E7%9A%84%E6%A8%A1%E5%9E%8Bebm%E9%9A%BE%E4%BB%A5%E8%AE%AD%E7%BB%83"><span class="toc-number">1.6.4.1.</span> <span class="toc-text">4.4.1为什么用于隐式策略的基于能量的模型(EBM)难以训练:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%A9%E6%95%A3%E7%AD%96%E7%95%A5%E5%92%8C-ddpm%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A5%BD%E8%AE%AD%E7%BB%83"><span class="toc-number">1.6.4.2.</span> <span class="toc-text">4.4.2扩散策略和 DDPM为什么好训练:</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8E%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA%E7%9A%84%E8%81%94%E7%B3%BB"><span class="toc-number">1.6.5.</span> <span class="toc-text">4.5与控制理论的联系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#evaluation"><span class="toc-number">1.7.</span> <span class="toc-text">5 Evaluation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BF%E7%9C%9F%E7%8E%AF%E5%A2%83%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.7.1.</span> <span class="toc-text">5.1仿真环境和数据集</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/27/%E8%B5%84%E6%96%99/%E5%91%BD%E4%BB%A42/" title="命令2">命令2</a><time datetime="2024-07-26T16:12:09.942Z" title="Created 2024-07-27 00:12:09">2024-07-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/22/mac%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/mac%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/" title="mac常见问题汇总">mac常见问题汇总</a><time datetime="2024-07-22T05:06:51.380Z" title="Created 2024-07-22 13:06:51">2024-07-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/28/vscode%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/vscode%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/" title="vscode插件开发">vscode插件开发</a><time datetime="2024-06-28T06:47:30.251Z" title="Created 2024-06-28 14:47:30">2024-06-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5/" title="强化学习相关概念">强化学习相关概念</a><time datetime="2024-06-28T04:03:18.846Z" title="Created 2024-06-28 12:03:18">2024-06-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/" title="机器学习相关概念">机器学习相关概念</a><time datetime="2024-06-26T09:09:56.000Z" title="Created 2024-06-26 17:09:56">2024-06-26</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By ALTNT</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>